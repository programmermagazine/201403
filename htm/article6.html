<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
  <link rel="stylesheet" href="../css/pmag.css" type="text/css" />
</head>
<body>
<div id="header_wrap">
   <h1><a href="https://www.facebook.com/groups/programmerMagazine">程式人雜誌</a> <sub> --  <a href="https://dl.dropbox.com/u/101584453/pmag/201403/htm/home.html">2014 年 3 月號</a> (開放公益出版品)</sub></h1>
</div>
<div id="content">
<div id="TOC">
<ul>
<li><a href="#講題分享---用-r-進行中文-text-mining-作者陳嘉葳taiwan-r-user-group">講題分享 - 用 R 進行中文 text Mining (作者:陳嘉葳@Taiwan R User Group)</a></li>
</ul>
</div>
<h2 id="講題分享---用-r-進行中文-text-mining-作者陳嘉葳taiwan-r-user-group"><a href="#講題分享---用-r-進行中文-text-mining-作者陳嘉葳taiwan-r-user-group">講題分享 - 用 R 進行中文 text Mining (作者:陳嘉葳@Taiwan R User Group)</a></h2>
<p>本文使用的分析方法，目前僅能在Windows上測試成功。</p>
<h3 id="簡介"><a href="#簡介">簡介</a></h3>
<p>現今網路上有大量文字資料,例如 ptt, facebook, 或 mobile01等討論網站上都有大量文字留言, 由於這些資料繁多雜亂, 我們可藉由文字探勘技術萃取出有用的訊息, 讓人們有效率掌握這些網路文字所提供的訊息。而R語言是一款非常適合資料分析的工具,有一系列文字探勘的套件可供使用,本文將簡單介紹中文文字探勘套件的使用方法。</p>
<h3 id="安裝需要工具"><a href="#安裝需要工具">安裝需要工具</a></h3>
<p>我的環境: Windows 7 + R 版本 2.15.3 + RStudio 0.98.484</p>
<p>安裝以下套件</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;rJava&quot;</span>)
<span class="kw">install.packages</span>(<span class="st">&quot;Rwordseg&quot;</span>, <span class="dt">repos=</span><span class="st">&quot;http://R-Forge.R-project.org&quot;</span>)
<span class="kw">install.packages</span>(<span class="st">&quot;tm&quot;</span>)
<span class="kw">install.packages</span>(<span class="st">&quot;tmcn&quot;</span>, <span class="dt">repos=</span><span class="st">&quot;http://R-Forge.R-project.org&quot;</span>, <span class="dt">type=</span><span class="st">&quot;source&quot;</span>)
<span class="kw">install.packages</span>(<span class="st">&quot;wordcloud&quot;</span>)
<span class="kw">install.packages</span>(<span class="st">&quot;XML&quot;</span>)
<span class="kw">install.packages</span>(<span class="st">&quot;RCurl&quot;</span>)</code></pre>
<p>Windows上安裝rJava的注意事項:</p>
<ul>
<li>將jvm.dll加到環境變數PATH之中</li>
<li>注意java的版本(32-bit or 64-bit)必須要和R一致 (Windows binary)之後再安裝，以避免</li>
</ul>
<h3 id="抓取ptt笨版文章列表"><a href="#抓取ptt笨版文章列表">抓取ptt笨版文章列表</a></h3>
<p>我們以分析ptt笨版文章為範例, 首先到ptt web 版抓取文章的url連結。 我們利用 RCurl套件的 getURL和 XML套件的 htmlParseApply 抓取笨版文章列表的 html網頁, 再用xpathSApply 去擷取出所有文章的url連結並儲存。 或是可以到<a href="https://dl.dropboxusercontent.com/u/21186660/doc.rar">已下載ptt笨版文章</a></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(XML)
<span class="kw">library</span>(RCurl)

data &lt;-<span class="st"> </span><span class="kw">list</span>()

for( i in <span class="dv">1058</span>:<span class="dv">1118</span>){
  tmp &lt;-<span class="st"> </span><span class="kw">paste</span>(i, <span class="st">&#39;.html&#39;</span>, <span class="dt">sep=</span><span class="st">&#39;&#39;</span>)
  url &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&#39;www.ptt.cc/bbs/StupidClown/index&#39;</span>, tmp, <span class="dt">sep=</span><span class="st">&#39;&#39;</span>)
  html &lt;-<span class="st"> </span><span class="kw">htmlParse</span>(<span class="kw">getURL</span>(url))
  url.list &lt;-<span class="st"> </span><span class="kw">xpathSApply</span>(html, <span class="st">&quot;//div[@class=&#39;title&#39;]/a[@href]&quot;</span>, xmlAttrs)
  data &lt;-<span class="st"> </span><span class="kw">rbind</span>(data, <span class="kw">paste</span>(<span class="st">&#39;www.ptt.cc&#39;</span>, url.list, <span class="dt">sep=</span><span class="st">&#39;&#39;</span>))
}
data &lt;-<span class="st"> </span><span class="kw">unlist</span>(data)</code></pre>
<p>下載列表中的笨版文章之後，接著才開始利用所有文章的url連結去抓所有文章的html網頁, 並用xpathSApply去解析出文章的內容並儲存。</p>
<pre class="sourceCode r"><code class="sourceCode r">getdoc &lt;-<span class="st"> </span>function(line){
  start &lt;-<span class="st"> </span><span class="kw">regexpr</span>(<span class="st">&#39;www&#39;</span>, line)[<span class="dv">1</span>]
  end &lt;-<span class="st"> </span><span class="kw">regexpr</span>(<span class="st">&#39;html&#39;</span>, line)[<span class="dv">1</span>]
  
  if(start !=<span class="st"> </span>-<span class="dv">1</span> &amp;<span class="st"> </span>end !=<span class="st"> </span>-<span class="dv">1</span>){
    url &lt;-<span class="st"> </span><span class="kw">substr</span>(line, start, end<span class="dv">+3</span>)
    html &lt;-<span class="st"> </span><span class="kw">htmlParse</span>(<span class="kw">getURL</span>(url), <span class="dt">encoding=</span><span class="st">&#39;UTF-8&#39;</span>)
    doc &lt;-<span class="st"> </span><span class="kw">xpathSApply</span>(html, <span class="st">&quot;//div[@id=&#39;main-content&#39;]&quot;</span>, xmlValue)
    name &lt;-<span class="st"> </span><span class="kw">strsplit</span>(url, <span class="st">&#39;/&#39;</span>)[[<span class="dv">1</span>]][<span class="dv">4</span>]
    <span class="kw">write</span>(doc, <span class="kw">gsub</span>(<span class="st">&#39;html&#39;</span>, <span class="st">&#39;txt&#39;</span>, name))
  }      
}</code></pre>
<p>開始下載文章</p>
<p>先用 <code>setwd(填入資料夾位置)</code> 這指令, 選定文件下載位置<br />或是用 <code>getwd()</code>確定目前的工作資料夾位置</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sapply</span>(data, getdoc)  </code></pre>
<h3 id="開始文字處理"><a href="#開始文字處理">開始文字處理</a></h3>
<p>首先載入以下text mining 套件</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tm)
<span class="kw">library</span>(tmcn)</code></pre>
<pre><code>## # tmcn Version: 0.1-2</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(Rwordseg)</code></pre>
<pre><code>## Loading required package: rJava
## # Version: 0.2-1</code></pre>
<p>匯入剛才抓完的笨版文章，doc 是儲存下載ptt文章的資料夾, 這些文章變成我們分析的語料庫。</p>
<pre class="sourceCode r"><code class="sourceCode r">d.corpus &lt;-<span class="st"> </span><span class="kw">Corpus</span>(<span class="kw">DirSource</span>(<span class="st">&quot;doc&quot;</span>), <span class="kw">list</span>(<span class="dt">language =</span> <span class="ot">NA</span>))</code></pre>
<h3 id="進行數據清理"><a href="#進行數據清理">進行數據清理</a></h3>
<p>1 清除標點符號, 數字</p>
<pre class="sourceCode r"><code class="sourceCode r">d.corpus &lt;-<span class="st"> </span><span class="kw">tm_map</span>(d.corpus, removePunctuation)
d.corpus &lt;-<span class="st"> </span><span class="kw">tm_map</span>(d.corpus, removeNumbers)</code></pre>
<p>2 清除大小寫英文與數字</p>
<pre class="sourceCode r"><code class="sourceCode r">d.corpus &lt;-<span class="st"> </span><span class="kw">tm_map</span>(d.corpus, function(word) {
    <span class="kw">gsub</span>(<span class="st">&quot;[A-Za-z0-9]&quot;</span>, <span class="st">&quot;&quot;</span>, word)
})</code></pre>
<h3 id="進行中文斷詞"><a href="#進行中文斷詞">進行中文斷詞</a></h3>
<p>首先，由於ptt有自己獨特的詞彙，例如發文不附沒圖、沒圖沒真相...等等，因此我們另外安裝 ptt 常用詞彙來協助斷詞。ptt常用詞彙可以從<a href="http://wubi.sogou.com/dict/cell.php?id=9182">搜狗細胞辭庫</a>下載 。</p>
<pre class="sourceCode r"><code class="sourceCode r">words &lt;-<span class="st"> </span><span class="kw">readLines</span>(<span class="st">&quot;http://wubi.sogou.com/dict/download_txt.php?id=9182&quot;</span>)
words &lt;-<span class="st"> </span><span class="kw">toTrad</span>(words)
<span class="kw">insertWords</span>(words)</code></pre>
<p>接著，我們利用我們 Rwordseg套件裡的segmentCN來進行斷詞。Rwordseg是<a href="http://jliblog.com/app/rwordseg">李艦</a>所撰寫的R套件，利用rJava去連結java分詞工具ansj來進行斷詞。 另外，斷詞後的詞彙有詞性，例如動詞、名詞、形容詞、介係詞等等，我們只挑出名詞來進行分析。</p>
<pre class="sourceCode r"><code class="sourceCode r">d.corpus &lt;-<span class="st"> </span><span class="kw">tm_map</span>(d.corpus[<span class="dv">1</span>:<span class="dv">100</span>], segmentCN, <span class="dt">nature =</span> <span class="ot">TRUE</span>)
d.corpus &lt;-<span class="st"> </span><span class="kw">tm_map</span>(d.corpus, function(sentence) {
    noun &lt;-<span class="st"> </span><span class="kw">lapply</span>(sentence, function(w) {
        w[<span class="kw">names</span>(w) ==<span class="st"> &quot;n&quot;</span>]
    })
    <span class="kw">unlist</span>(noun)
})
d.corpus &lt;-<span class="st"> </span><span class="kw">Corpus</span>(<span class="kw">VectorSource</span>(d.corpus))</code></pre>
<p>接著進行清除停用字符，停用字符指的是一些文章中常見的單字，但卻無法提供我們資訊的冗字。例如有些、以及、因此...等等字詞。</p>
<pre class="sourceCode r"><code class="sourceCode r">myStopWords &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">stopwordsCN</span>(), <span class="st">&quot;編輯&quot;</span>, <span class="st">&quot;時間&quot;</span>, <span class="st">&quot;標題&quot;</span>, <span class="st">&quot;發信&quot;</span>, <span class="st">&quot;實業&quot;</span>, <span class="st">&quot;作者&quot;</span>)
d.corpus &lt;-<span class="st"> </span><span class="kw">tm_map</span>(d.corpus, removeWords, myStopWords)</code></pre>
<p>我們可以看看有哪些停用字符，這裡抽出前20個停用字符來看</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(myStopWords, <span class="dv">20</span>)</code></pre>
<pre><code>##  [1] &quot;第二&quot;     &quot;一番&quot;     &quot;一直&quot;     &quot;一&lt;U+4E2A&gt;&quot; &quot;一些&quot;     &quot;&lt;U+8BB8&gt;多&quot;
##  [7] &quot;种&quot;       &quot;有的是&quot;   &quot;也就是&lt;U+8BF4&gt;&quot; &quot;末&quot;       &quot;啊&quot;       &quot;阿&quot;      
## [13] &quot;哎&quot;       &quot;哎呀&quot;     &quot;哎&lt;U+54DF&gt;&quot; &quot;唉&quot;       &quot;俺&quot;       &quot;俺&lt;U+4EEC&gt;&quot;
## [19] &quot;按&quot;       &quot;按照&quot;</code></pre>
<h3 id="建立-termdocumentmatrix"><a href="#建立-termdocumentmatrix">建立 TermDocumentMatrix</a></h3>
<p>中文斷詞結束後，我們用矩陣將結果儲存起來。TermDocumentMatrix 指的是關鍵字為列，文件是行的矩陣。儲存的數字是關鍵字在這些文件中出現的次數。其中 wordLengths=c(2,Inf) 表示我們挑至少兩個字的詞。</p>
<pre class="sourceCode r"><code class="sourceCode r">tdm &lt;-<span class="st"> </span><span class="kw">TermDocumentMatrix</span>(d.corpus, <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">wordLengths =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="ot">Inf</span>)))</code></pre>
<p>我們可以看看TermDocumentMatrix裡面，前兩篇文章的前10個關鍵字</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">inspect</span>(tdm[<span class="dv">1</span>:<span class="dv">10</span>, <span class="dv">1</span>:<span class="dv">2</span>])</code></pre>
<pre><code>## A term-document matrix (10 terms, 2 documents)
## 
## Non-/sparse entries: 3/17
## Sparsity           : 85%
## Maximal term length: 3 
## Weighting          : term frequency (tf)
## 
##         Docs
## Terms    M.1384834727.A.0CB.txt M.1384838698.A.957.txt
##   一生                        0                      0
##   一家                        1                      0
##   一家子                      0                      0
##   一線                        0                      0
##   人士                        0                      0
##   人才                        0                      0
##   人中                        0                      0
##   人文                        0                      0
##   人民                        0                      1
##   人生                        0                      2</code></pre>
<h3 id="畫出關鍵字詞雲"><a href="#畫出關鍵字詞雲">畫出關鍵字詞雲</a></h3>
<p>我們利用 wordcloud 套件，畫出在所有文件中出現次數超過10次的名詞。出現次數越多，字體就會呈現越大。</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(wordcloud)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(tdm)
v &lt;-<span class="st"> </span><span class="kw">sort</span>(<span class="kw">rowSums</span>(m1), <span class="dt">decreasing =</span> <span class="ot">TRUE</span>)
d &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">word =</span> <span class="kw">names</span>(v), <span class="dt">freq =</span> v)
<span class="kw">wordcloud</span>(d$word, d$freq, <span class="dt">min.freq =</span> <span class="dv">10</span>, <span class="dt">random.order =</span> F, <span class="dt">ordered.colors =</span> F, 
    <span class="dt">colors =</span> <span class="kw">rainbow</span>(<span class="kw">length</span>(<span class="kw">row.names</span>(m1))))</code></pre>
<div class="figure">
<img src="../img/unnamed-chunk-13.jpg" alt="plot of chunk unnamed-chunk-13" /><p class="caption">plot of chunk unnamed-chunk-13</p>
</div>
<p>這邊看到百合出現次數非常多，原因是因為一位叫小百合的網友所發的po文被鄉民推爆，留言當中也重複出現小百合的緣故。</p>
<h3 id="尋找關鍵字之間的關聯"><a href="#尋找關鍵字之間的關聯">尋找關鍵字之間的關聯</a></h3>
<p>當我們利用wordcloud 知道哪些關鍵字常出現後，接著可能想知道哪些字與它有關聯。 因此我們先建出DocumentTermMatrix，這是以文件名稱為列，關鍵字為欄的矩陣。</p>
<pre class="sourceCode r"><code class="sourceCode r">d.dtm &lt;-<span class="st"> </span><span class="kw">DocumentTermMatrix</span>(d.corpus, <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">wordLengths =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="ot">Inf</span>)))
<span class="kw">inspect</span>(d.dtm[<span class="dv">1</span>:<span class="dv">10</span>, <span class="dv">1</span>:<span class="dv">2</span>])</code></pre>
<pre><code>## A document-term matrix (10 documents, 2 terms)
## 
## Non-/sparse entries: 1/19
## Sparsity           : 95%
## Maximal term length: 2 
## Weighting          : term frequency (tf)
## 
##                         Terms
## Docs                     一生 一家
##   M.1384834727.A.0CB.txt    0    1
##   M.1384838698.A.957.txt    0    0
##   M.1384840050.A.414.txt    0    0
##   M.1384840304.A.EF5.txt    0    0
##   M.1384842495.A.5B8.txt    0    0
##   M.1384842609.A.A5B.txt    0    0
##   M.1384847473.A.6A5.txt    0    0
##   M.1384847771.A.729.txt    0    0
##   M.1384848469.A.AD8.txt    0    0
##   M.1384849471.A.B71.txt    0    0</code></pre>
<p>可以用 findFreqTerms 看看在所有文件裡出現30次以上的關鍵字有哪些。</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">findFreqTerms</span>(d.dtm, <span class="dv">30</span>)</code></pre>
<pre><code>## [1] &quot;同學&quot; &quot;百合&quot; &quot;老闆&quot; &quot;朋友&quot; &quot;東西&quot; &quot;時候&quot; &quot;閃光&quot; &quot;問卷&quot; &quot;結果&quot;</code></pre>
<p>再來可以用 findAssocs 找出最常與&quot;同學&quot;關程度0.5以上的關鍵字。</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">findAssocs</span>(d.dtm, <span class="st">&quot;同學&quot;</span>, <span class="fl">0.5</span>)</code></pre>
<pre><code>## 同學.原因 
##      0.56</code></pre>
<h3 id="結尾"><a href="#結尾">結尾</a></h3>
<p>以上我們介紹了如何將中文文章進行清理、斷詞等處理，最後轉換成矩陣，再進行一些簡單分析與繪圖。本文介紹之操作，還可以繼續進行關鍵字分群、主題模型、情緒分析等進階應用，有興趣繼續深入, 可以自行搜尋 tm, tmcn, Rwordseg 這三個套件，可以發現許多資源自行學習。</p>
<h3 id="作者"><a href="#作者">作者</a></h3>
<ul>
<li>陳嘉葳 : 國立高雄大學資管所, <a href="https://www.facebook.com/groups/680228652018057/">Kaohsiung useR! Meetup</a>, <a href="http://www.meetup.com/Taiwan-R">Taiwan R User Group</a></li>
</ul>
<h3 id="參考資料"><a href="#參考資料">參考資料</a></h3>
<ul>
<li><a href="http://jliblog.com/app/rwordseg">Rwordseg</a><br /></li>
<li><a href="https://docs.google.com/viewer?url=http%3A%2F%2Fevent.twdatascience.org%2Fimages%2Fr_taiwan%2Fshare%2F%25E5%25B0%2588%25E9%25A1%258C%25E6%25BC%2594%25E8%25AC%259B2RTaiwan2013_%25E6%259D%258E%25E8%2589%25A6.pdf">中文文字資料探勘 (英國Mango Solutions上海分公司資深顧問李艦)</a><br /></li>
<li><a href="www.youtube.com/watch?v=TcMao3r6jYY">MLDM Monday - 如何用 R 作中文斷詞</a></li>
<li><a href="http://stackoverflow.com/questions/7019912/using-the-rjava-package-on-win7-64-bit-with-r">using-the-rjava-package-on-win7-64-bit-with-r</a></li>
</ul>
</div>
<div id="footer">
<a href="https://www.facebook.com/groups/programmerMagazine/">程式人雜誌</a> ，採用 <a href="http://creativecommons.org/licenses/by-sa/3.0/tw/ ">創作共用：姓名標示、相同方式分享</a> 授權，歡迎加入 <a href="https://www.facebook.com/groups/programmerMagazine/">雜誌社團</a>
</div>
</body>
</html>
